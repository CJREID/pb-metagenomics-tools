{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare-kreport-taxonomic-profiles.ipynb\n",
    "\n",
    "The goal of this Jupyter notebook is to facilitate easy comparisons of the taxonomic \n",
    "profiles of multiple metagenomic samples. These analyses require kraken-report \n",
    "(kreport) format files as inputs, and the analyses can be performed for any \n",
    "taxonomic rank in the kreport files (strain, species, genus, family, etc.). \n",
    "\n",
    "This notebook will also provide a summary of how many reads were assigned across taxonomic ranks, and the number of unique taxa assigned across taxonomic ranks.\n",
    "\n",
    "Running the notebook requires the pandas, seaborn, and matplotlib Python libraries.\n",
    "\n",
    "The kreport format is standard for many profilers (Kraken, Bracken, Centrifuge, MMSeqs2), and \n",
    "there are conversion scripts available for Metamaps, MetaPhlAn3, and MEGAN in:\n",
    "https://github.com/PacificBiosciences/pb-metagenomics-tools/tree/master/pb-metagenomics-scripts\n",
    "The PacBio MEGAN-LR workflows also produce kreport output formats:\n",
    "https://github.com/PacificBiosciences/pb-metagenomics-tools/\n",
    "\n",
    "To run your own analyses, you will need to edit the sample/file path information. \n",
    "You can generate counts at different taxnomic levels using the get_all_dfs() function.\n",
    "There are examples of how to do this at the species and genus levels, along with\n",
    "how to save the count tables and create/save stacked barplot figures. \n",
    "\n",
    "**To make high-quality plots, you will likely need to change aspects of the plot parameters. This will depend on the number of samples in your dataset as well as their microbial diversity. There are clear explanations in the species level analysis for how to change different plot parameters.**\n",
    "\n",
    "Daniel Portik \n",
    "\n",
    "Bioinformatics Scientist, Pacific Biosciences\n",
    "\n",
    "dportik@pacificbiosciences.com\n",
    "\n",
    "05/2021\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"Top\"></a>\n",
    "\n",
    "+ [Entering Sample Information](#ESI)\n",
    "+ [Functions for Interpreting kreports](#FIK)\n",
    "+ [Read Utilization Analysis](#RUA)\n",
    "    + [Plot Percent Reads per Rank](#PRR)\n",
    "    + [Plot Unique Taxa per Rank](#PTR)\n",
    "+ [Species Level Analysis](#SP)\n",
    "    + [Creating dataframes](#SPDF)\n",
    "    + [Stacked Barplots](#SPSB)\n",
    "    + [Heatmaps](#SPH)\n",
    "    + [Barplot with Absolute Counts](#SPAB)\n",
    "+ [Genus Level Analysis](#GN)\n",
    "    + [Creating dataframes](#GNDF)\n",
    "    + [Stacked Barplots](#GNSB)\n",
    "    + [Heatmaps](#GNH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter sample and file information here <a name=\"ESI\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the full path to each kreport to include below. \n",
    "# In this example we are using four files. The variable name\n",
    "# is ideally what you want to call the sample in the analysis.\n",
    "\n",
    "BC_138274 = '/Users/dportik/Documents/Projects/Datasets/CID_138274.megan-RMA-c2c.kreport.txt'\n",
    "BC_138390 = '/Users/dportik/Documents/Projects/Datasets/CID_138390.megan-RMA-c2c.kreport.txt'\n",
    "BC_139369 = '/Users/dportik/Documents/Projects/Datasets/CID_139369.megan-RMA-c2c.kreport.txt'\n",
    "BC_139445 = '/Users/dportik/Documents/Projects/Datasets/CID_139445.megan-RMA-c2c.kreport.txt'\n",
    "\n",
    "# Create a dictionary with string labels for the files as keys and the \n",
    "# a list for the values. The first item in the list is the file path, \n",
    "# and the second item should be the number of reads in the sample.\n",
    "# The string labels will be used to label the samples in the resulting \n",
    "# tables and figures.\n",
    "\n",
    "# Follow the format below for your own data.\n",
    "\n",
    "file_dict = {\"BC_138274\": [BC_138274, 1792146], \n",
    "             \"BC_138390\": [BC_138390, 1687238], \n",
    "             \"BC_139369\": [BC_139369, 1904159], \n",
    "             \"BC_139445\": [BC_139445, 1767289]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for interpreting kreports <a name=\"FIK\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The series of functions will create three types of pandas dataframes with taxon \n",
    "# counts for a specified taxonomic rank. The first dataframe contains absolute counts of \n",
    "# the taxa across all samples. It can be exported as a CSV file, and is also transformed to \n",
    "# make the second and third dataframes. These additional dataframes will contain the \n",
    "# absolute or normalized counts in a transposed format that is used to make the stacked\n",
    "# barplot figures. Do not edit these functions!\n",
    "\n",
    "def get_unique_taxa_at_rank(file_dict, rank):\n",
    "    \"\"\"\n",
    "    Function to obtain all unique taxon names at a given rank \n",
    "    for a set of kreport files provided in file_dict. Returns \n",
    "    sorted list of unique taxon names.\n",
    "    \n",
    "    :param file_dict: dictionary with string label as key and file path as val\n",
    "    :param rank: desired taxonomic rank (e.g., 'S1', 'S', 'G', 'F', etc.)\n",
    "    :return: sorted list of unique taxon names at rank\n",
    "    \"\"\"\n",
    "    # initiate empty set for taxon names\n",
    "    taxon_set = set()\n",
    "    \n",
    "    # iterate over the file dictionary\n",
    "    for key, val in file_dict.items():\n",
    "        \n",
    "        # create a pandas dataframe, remove whitespace to clean names column of kreport \n",
    "        df = pd.read_csv(val[0], sep = '\\t', header=None, skipinitialspace=True,\n",
    "                         names = ['proportion', 'cumulative_count', 'level_count', 'rank', 'taxid', 'name'])\n",
    "        \n",
    "        # get all unique taxon names at rank, add to set\n",
    "        taxa = [t for t in (df.loc[df['rank'] == rank, 'name']).unique()]\n",
    "        taxon_set.update(taxa)\n",
    "    \n",
    "    # return sorted list of taxon names\n",
    "    return sorted(taxon_set)\n",
    "\n",
    "def make_rank_dataframe(file_dict, rank):\n",
    "    \"\"\"\n",
    "    Function to create a dataframe with taxon counts for \n",
    "    all kreport files in file_dict at a given taxonomic rank. \n",
    "    Returns pandas dataframe.\n",
    "    \n",
    "    :param file_dict: dictionary with string label as key and file path as val\n",
    "    :param rank: desired taxonomic rank (e.g., 'S1', 'S', 'G', 'F', etc.)\n",
    "    :return: pandas dataframe of taxon counts for specified rank\n",
    "    \"\"\"\n",
    "    \n",
    "    # initiate empty dictionary\n",
    "    taxon_count_dict = {}\n",
    "    \n",
    "    # get taxon names to use for this rank\n",
    "    taxon_list = get_unique_taxa_at_rank(file_dict, rank)\n",
    "    \n",
    "    # iterate over the file dictionary\n",
    "    for key, val in file_dict.items():\n",
    "        \n",
    "        # add this sample as a key in the taxon count dictionary\n",
    "        # value is an empty list that will be filled with taxon counts\n",
    "        # in the order of the taxon_list\n",
    "        taxon_count_dict[key] = []\n",
    "        \n",
    "        # make temp dataframe, remove whitespace to clean names column of kreport \n",
    "        df = pd.read_csv(val[0], sep = '\\t', header=None, skipinitialspace=True, \n",
    "                         names = ['proportion', 'cumulative_count', 'level_count', 'rank', 'taxid', 'name'])\n",
    "        \n",
    "        # iterate over taxon names \n",
    "        for taxon in taxon_list:\n",
    "            # make a subframe with matched name\n",
    "            temp = df.loc[df['name'] == taxon]\n",
    "            # add the cumulative count for the taxon name to the dict list\n",
    "            # this should only be a single name, taking sum as easy way to get integer\n",
    "            taxon_count_dict[key].append(temp.loc[df['rank'] == rank, 'cumulative_count'].sum())\n",
    "    \n",
    "    # create new dataframe from the dictionaries constructed\n",
    "    df_taxa = pd.DataFrame.from_dict(taxon_count_dict)\n",
    "    \n",
    "    # add in a column with the taxon labels\n",
    "    df_taxa.insert(0, 'Taxa', taxon_list)\n",
    "    \n",
    "    # return the taxon dataframe\n",
    "    return df_taxa\n",
    "\n",
    "def prepare_plotting_dfs(df, file_dict, sortby=list(file_dict.keys())):\n",
    "    # transpose dataframe, sort counts, and add new column names\n",
    "    df_transpose = df.sort_values(by=sortby, ascending=False).set_index('Taxa').transpose().rename_axis('Samples', axis=1)\n",
    "    # normalize the species counts of each sample 100%\n",
    "    df_transpose_norm = df_transpose.apply(lambda x: x*100/sum(x), axis=1)\n",
    "    \n",
    "    return df_transpose, df_transpose_norm\n",
    "\n",
    "def get_all_dfs(file_dict, rank, sortby=list(file_dict.keys())):\n",
    "    df_one = make_rank_dataframe(file_dict, rank)\n",
    "    df_two, df_three = prepare_plotting_dfs(df_one, file_dict, sortby=sortby)\n",
    "    return df_one, df_two, df_three\n",
    "    \n",
    "    \n",
    "##############################################################################\n",
    "# This function will count the number of reads assigned at each rank level,\n",
    "# as well as the number of unique taxa occurring at each rank level.\n",
    "\n",
    "\n",
    "def get_reads_to_ranks(file_dict):\n",
    "    \n",
    "    rank_read_count_dict, rank_taxa_count_dict = {}, {}\n",
    "    \n",
    "    for key, val in file_dict.items():\n",
    "        # insert dict key with empty list\n",
    "        rank_read_count_dict[key] = []\n",
    "        rank_taxa_count_dict[key] = []\n",
    "\n",
    "        # create dataframe\n",
    "        df = pd.read_csv(val[0], sep = '\\t', header=None,\n",
    "                         names = ['proportion', 'cumulative_count', 'level_count', 'rank', 'taxid', 'name'])\n",
    "\n",
    "        # iterate over desired ranks\n",
    "        for r in ['S1', 'S', 'G', 'F', 'O', 'C', 'P', 'K']:\n",
    "\n",
    "            # get number of reads assigned to all taxa at this rank level\n",
    "            # we use level counts rather than cumulative counts here\n",
    "            rank_readtotal = round((df.loc[df['rank'] == r, 'level_count'].sum() / val[1]) * 100, 1)\n",
    "            # add to dictionary list\n",
    "            rank_read_count_dict[key].append(rank_readtotal)\n",
    "\n",
    "            # get number of unique names per rank\n",
    "            rank_namecount = (df['rank'] == r).sum()\n",
    "            # add to dictionary list\n",
    "            rank_taxa_count_dict[key].append(rank_namecount)\n",
    "            \n",
    "        # convert dictionary to dataframe and insert new column in with rank names\n",
    "    # do for read counts\n",
    "    df_rank_read_count = pd.DataFrame.from_dict(rank_read_count_dict)\n",
    "    df_rank_read_count.insert(0, 'Rank', ['S1', 'S', 'G', 'F', 'O', 'C', 'P', 'K'])\n",
    "\n",
    "    # same for taxa counts\n",
    "    df_rank_taxa_count = pd.DataFrame.from_dict(rank_taxa_count_dict)\n",
    "    df_rank_taxa_count.insert(0, 'Rank', ['S1', 'S', 'G', 'F', 'O', 'C', 'P', 'K'])\n",
    "    \n",
    "    return df_rank_read_count, df_rank_taxa_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Utilization Analysis <a name=\"RUA\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are attempting to understand how many reads were assigned at particular\n",
    "# taxonomic ranks, and how many unique taxa were inferred at different ranks.\n",
    "\n",
    "# Use the get_reads_to_ranks() function to return the dataframes for plotting.\n",
    "# You won't need to change anything here.\n",
    "df_rank_read_count, df_rank_taxa_count = get_reads_to_ranks(file_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot percent of reads assigned across ranks <a name=\"PRR\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# do a quick manipulation of the dataframe for correct plotting orientation\n",
    "df_rank_read_count_it = df_rank_read_count.set_index('Rank').transpose().rename_axis('Sample', axis=1)\n",
    "\n",
    "\n",
    "# Create the horizontal stacked bar plot using the pandas .plot.barh() function with the following args:\n",
    "\n",
    "# stacked: controls whether or not to create a stacked barplot\n",
    "# figsize: the dimensions of the figure, in (width, height)\n",
    "# width: this controls the width of the bars, 1 = no separation between them, <1 puts spacing in\n",
    "# color: sets the colors, we are setting a seaborn palette here\n",
    "# fontsize: the size of sample labels (values = xx-small, x-small, small, medium, large, x-large, xx-large)\n",
    "# edgecolor: controls the color of lines separating colors within bars, as well as bar outline\n",
    "# linewidth: the line size for the edgecolor\n",
    "# ylim: set limits for y-axis\n",
    "\n",
    "ax = df_rank_read_count_it.plot.bar(stacked=True, figsize=(4,7), width=0.8, color=sns.color_palette(\"Spectral_r\",8), \n",
    "                                    fontsize='large', edgecolor='black', linewidth=0.5,\n",
    "                                    title='Percent-Reads-per-Rank', ylim=(0,100))\n",
    "\n",
    "# for vertical plot, we need to reverse the legend labels, start by getting these objects\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# add reversed(handles) and reversed(labels) to the legend arguments\n",
    "# this controls the placement of the legend (bbox_to_anchor), as well as font (fontsize), \n",
    "# number of columns for labels (ncol), and spacing (labelspacing)\n",
    "ax.legend(reversed(handles), reversed(labels), bbox_to_anchor=(1,1), \n",
    "          fontsize='large', ncol=1, labelspacing=0.3)\n",
    "\n",
    "# adjust the appearance of the x-labels\n",
    "ax.set_xticklabels(df_rank_read_count_it.index, rotation=45, ha='right')\n",
    "\n",
    "# Use this to save the plot to file\n",
    "ax.figure.savefig('Percent-Reads-per-Rank.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot number of taxa assigned across ranks <a name=\"PTR\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# do a quick manipulation of the dataframe for correct plotting orientation\n",
    "df_rank_taxa_count_it = df_rank_taxa_count.set_index('Rank').transpose().rename_axis('Sample', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Create the horizontal stacked bar plot using the pandas .plot.barh() function with the following args:\n",
    "\n",
    "# stacked: controls whether or not to create a stacked barplot\n",
    "# figsize: the dimensions of the figure, in (width, height)\n",
    "# width: this controls the width of the bars, 1 = no separation between them, <1 puts spacing in\n",
    "# color: sets the colors, we are setting a seaborn palette here\n",
    "# fontsize: the size of sample labels (values = xx-small, x-small, small, medium, large, x-large, xx-large)\n",
    "# edgecolor: controls the color of lines separating colors within bars, as well as bar outline\n",
    "# linewidth: the line size for the edgecolor\n",
    "\n",
    "ax = df_rank_taxa_count_it.plot.bar(stacked=True, figsize=(4,7), width=0.8, color=sns.color_palette(\"gist_stern_r\",8), \n",
    "                                    fontsize='large', edgecolor='black', linewidth=0.5,\n",
    "                                    title='Percent-Reads-per-Rank')\n",
    "\n",
    "# for vertical plot, we need to reverse the legend labels, start by getting these objects\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# add reversed(handles) and reversed(labels) to the legend arguments\n",
    "# this controls the placement of the legend (bbox_to_anchor), as well as font (fontsize), \n",
    "# number of columns for labels (ncol), and spacing (labelspacing)\n",
    "ax.legend(reversed(handles), reversed(labels), bbox_to_anchor=(1,1), \n",
    "          fontsize='large', ncol=1, labelspacing=0.3)\n",
    "\n",
    "# adjust the appearance of the x-labels\n",
    "ax.set_xticklabels(df_rank_taxa_count_it.index, rotation=45, ha='right')\n",
    "\n",
    "# Use this to save the plot to file\n",
    "ax.figure.savefig('Percent-Taxa-per-Rank.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis at the SPECIES level <a name=\"SP\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECIES: Create species-level dataframes <a name=\"SPDF\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This demonstrates how to use the main function get_all_dfs() to create \n",
    "# the comparison dataframes. We will start the demonstration for the \n",
    "# species level.\n",
    "\n",
    "# To generate the dataframes, we use the following function: \n",
    "# get_all_dfs(file_dict, rank, sortby='Name')\n",
    "#    the first positional argument is file_dict (leave unchanged)\n",
    "#    the second positional argument is the rank desired ('S1', 'S', 'G', 'F', etc.)\n",
    "#    the optional argument sortby can be used to specify one of the samples to sort \n",
    "#        abundances by, which must be a key name in file_dict\n",
    "# The function returns three dataframes, so three variable names must be specified\n",
    "\n",
    "# Here is the basic usage to get dataframes for species level taxa:\n",
    "df_sp, df_sp_plot, df_sp_plot_norm = get_all_dfs(file_dict, 'S')\n",
    "# In the above example, we labeled the three dataframes returned by the function as:\n",
    "# df_sp, df_sp_plot, and df_sp_plot_norm.\n",
    "\n",
    "# Below is the same example but with sorting by abundances in sample \"CID_139445\", un-hash to run:\n",
    "# df_sp, df_sp_plot, df_sp_plot_norm = get_all_dfs(file_dict, 'S', sortby=\"CID_139445\")\n",
    "# Make sure if you use the optional argument that you specify a label name/key in the file_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first type of dataframe. Here, samples are the columns and taxa form the rows. \n",
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the second dataframe. Notice it is a transposed version of the first one.\n",
    "# Here, taxa are columns and samples are the rows.\n",
    "df_sp_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview the third dataframe. This is the same format as above,\n",
    "# but the values have been normalized so counts for each sample \n",
    "# total to 100. \n",
    "df_sp_plot_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECIES: Saving the dataframes to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save any of the above dataframes, use the df.to_csv() method\n",
    "\n",
    "# for the df_sp, we don't want to include the index (which is just integers)\n",
    "# we can also specify tab-delimited using the sep argument:\n",
    "df_sp.to_csv(\"Species-Absolute-Abundance-Counts.txt\", index=False, sep='\\t')\n",
    "\n",
    "# for the df_sp_plot and df_sp_plot_norm dataframes, keep the index (which is the sample names):\n",
    "df_sp_plot.to_csv(\"Species-Absolute-Abundance-Counts-Transposed.txt\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECIES stacked barplots <a name=\"SPSB\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a HORIZONTAL stacked barplot using the NORMALIZED COUNT dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# Create the horizontal stacked bar plot using the pandas .plot.barh() function with the following args:\n",
    "\n",
    "# stacked: controls whether or not to create a stacked barplot\n",
    "# figsize: the dimensions of the figure, in (width, height)\n",
    "# width: this controls the width of the bars, 1 = no separation between them, <1 puts spacing in\n",
    "# color: sets the colors, we refer to pal which was set above\n",
    "# fontsize: the size of sample labels (values = xx-small, x-small, small, medium, large, x-large, xx-large)\n",
    "# edgecolor: controls the color of lines separating colors within bars, as well as bar outline\n",
    "# linewidth: the line size for the edgecolor\n",
    "\n",
    "ax = df_sp_plot_norm.plot.barh(stacked=True, figsize=(20,5), width=0.8, \n",
    "                               color=sns.color_palette(\"tab20\"), fontsize='large', \n",
    "                               edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# these commands eliminate the bounding box for the barplot\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# this controls the placement of the legend (bbox_to_anchor), as well as font (fontsize), \n",
    "# number of columns for labels (ncol), and spacing (labelspacing)\n",
    "ax.legend(bbox_to_anchor=(1,-0.10), fontsize='x-small', ncol=7, labelspacing=0.3)\n",
    "\n",
    "# You can save the plot using the following:\n",
    "ax.figure.savefig('Species-Abundances-Normalized-Horizontal.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a VERTICAL stacked barplot using the NORMALIZED COUNT dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# Create the vertical stacked bar plot using the pandas .plot.bar() function with the following args:\n",
    "\n",
    "# stacked: controls whether or not to create a stacked barplot\n",
    "# figsize: the dimensions of the figure, in (width, height)\n",
    "# width: this controls the width of the bars, 1 = no separation between them, <1 puts spacing in\n",
    "# color: sets the colors, we refer to pal which was set above\n",
    "# fontsize: the size of sample labels (values = xx-small, x-small, small, medium, large, x-large, xx-large)\n",
    "# edgecolor: controls the color of lines separating colors within bars, as well as bar outline\n",
    "# linewidth: the line size for the edgecolor\n",
    "\n",
    "ax = df_sp_plot_norm.plot.bar(stacked=True, figsize=(5,15), width=0.8, \n",
    "                              color=sns.color_palette(\"tab20\"), fontsize='large', \n",
    "                              edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# these commands eliminate the bounding box for the barplot\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# for vertical plot, we need to reverse the legend labels, start by getting these objects\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# and add reversed(handles) and reversed(labels) to the legend arguments\n",
    "# this controls the placement of the legend (bbox_to_anchor), as well as font (fontsize), \n",
    "# number of columns for labels (ncol), and spacing (labelspacing)\n",
    "ax.legend(reversed(handles), reversed(labels), bbox_to_anchor=(1,0.9), \n",
    "          fontsize='x-small', ncol=1, labelspacing=0.3)\n",
    "\n",
    "# You can save the above plot using the following:\n",
    "ax.figure.savefig('Species-Abundances-Normalized-Vertical.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECIES heatmaps <a name=\"SPH\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a HORIZONTAL heatmap using the NORMALIZED COUNT dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# set the size of the figure first\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "\n",
    "# use seaborn to generate the heatmap, set color to Blues\n",
    "sns.heatmap(df_sp_plot_norm, cmap=\"Blues\", linewidth=0.1, robust=True)\n",
    "\n",
    "# these commands clean up aspects of the tick labels\n",
    "ax.set_yticklabels(df_sp_plot_norm.index, rotation=0, ha='right', fontsize='medium')\n",
    "ax.set_xticklabels(df_sp_plot_norm, rotation=45, ha='right', fontsize='x-small')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "# You can save the plot using the following:\n",
    "ax.figure.savefig('Species-Heatmap-Horizontal.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a VERTICAL heatmap using the NORMALIZED COUNT dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "# set the size of the figure first\n",
    "fig, ax = plt.subplots(figsize=(4, 16))\n",
    "\n",
    "# use seaborn to generate the heatmap, set color to Blues\n",
    "sns.heatmap(df_sp_plot_norm.transpose(), cmap=\"Blues\", linewidth=0.1, robust=True)\n",
    "\n",
    "# these commands clean up aspects of the tick labels\n",
    "ax.set_xticklabels(df_sp_plot_norm.transpose(), rotation=45, ha='right', fontsize='small')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "# You can save the plot using the following:\n",
    "ax.figure.savefig('Species-Heatmap-Vertical.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a HORIZONTAL stacked barplot using the ABSOLUTE COUNT dataframe. <a name=\"SPAB\"></a>\n",
    "\n",
    "This is probably not a very useful plot if your samples have different numbers of reads, but it is provided as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this plot, we don't expect the stacked bars to be the same lengths.\n",
    "\n",
    "# All the same arguments are used, but we use the df_sp_plot dataframe instead\n",
    "# of the df_sp_plot_norm dataframe\n",
    "\n",
    "pal = sns.color_palette(\"tab20\")\n",
    "ax = df_sp_plot.plot.barh(stacked=True, figsize=(20,5), width=0.8, \n",
    "                          color=sns.color_palette(\"tab20\"), fontsize='large', \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1,-0.10), fontsize='x-small', ncol=7, labelspacing=0.3)\n",
    "\n",
    "# You can save the above plot using the following:\n",
    "ax.figure.savefig('Species-Abundances-Absolute-Horizontal.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis at the GENUS level <a name=\"GN\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a taxon dataframe for the GENUS level <a name=\"GNDF\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing, but for the genus level\n",
    "\n",
    "# here is the basic usage to get dataframes for genus level taxa\n",
    "df_gn, df_gn_plot, df_gn_plot_norm = get_all_dfs(file_dict, 'G')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview the first dataframe. Here, samples are the columns and taxa form the rows.\n",
    "df_gn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save genus counts to csv\n",
    "df_gn.to_csv(\"Genus-Absolute-Abundance-Counts.txt\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENUS stacked barplots <a name=\"GNSB\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a HORIZONTAL stacked barplot using the NORMALIZED COUNT dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "ax = df_gn_plot_norm.plot.barh(stacked=True, figsize=(20,5), width=0.8, \n",
    "                               color=sns.color_palette(\"tab20\"), fontsize='large', \n",
    "                               edgecolor='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1,-0.10), fontsize='small', ncol=7, labelspacing=0.1)\n",
    "ax.figure.savefig('Genus-Abundances-Normalized-Horizontal.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a VERTICAL stacked barplot using the NORMALIZED COUNT dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "ax = df_gn_plot_norm.plot.bar(stacked=True, figsize=(5,15), width=0.8, \n",
    "                              color=sns.color_palette(\"tab20\"), fontsize='large', \n",
    "                              edgecolor='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(reversed(handles), reversed(labels), bbox_to_anchor=(1,0.9), \n",
    "          fontsize='small', ncol=1, labelspacing=0.3)\n",
    "ax.figure.savefig('Genus-Abundances-Normalized-Vertical.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENUS heatmaps <a name=\"GNH\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a HORIZONTAL heatmap using the NORMALIZED COUNT dataframe. <a name=\"GNHH\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "sns.heatmap(df_gn_plot_norm, cmap=\"Blues\", linewidth=0.1, robust=True)\n",
    "ax.set_yticklabels(df_gn_plot_norm.index, rotation=0, ha='right', fontsize='medium')\n",
    "ax.set_xticklabels(df_gn_plot_norm, rotation=45, ha='right', fontsize='small')\n",
    "plt.show()\n",
    "ax.figure.savefig('Genus-Heatmap-Horizontal.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a VERTICAL heatmap using the NORMALIZED COUNT dataframe. <a name=\"GNVH\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here you will need to potentially change some of the argument values \n",
    "# depending on the number of samples and taxa in your dataset.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 10))\n",
    "sns.heatmap(df_gn_plot_norm.transpose(), cmap=\"Blues\", linewidth=0.1, robust=True)\n",
    "ax.set_xticklabels(df_gn_plot_norm.transpose(), rotation=45, ha='right', fontsize='small')\n",
    "plt.show()\n",
    "ax.figure.savefig('Genus-Heatmap-Vertical.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
