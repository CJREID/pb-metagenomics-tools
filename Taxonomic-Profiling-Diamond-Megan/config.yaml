diamond:
  # Specify the number of chunks to break each fasta file into. The default is 4, which is
  # optimal for a fasta of 2.5 million HiFi reads. Smaller files can run faster with fewer 
  # chunks (e.g., 2 or 1). Larger files (consisting of multiple sequencing cells) may benefit 
  # from more chunks, but 9 is the absolute upper limit for any workflow (10 will cause errors).
  # Using a chunk size of 1 means the entire fasta file will be used.
  # DO NOT OVER SPLIT your fasta file, or this workflow will run substantially slower. 
  chunks: 4

  # Provide the full path to the diamond-indexed database.
  # We recommend downloading the NCBI nr database from: ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz*
  # Please note the gzipped nr database as of July 2020 was 82GB in size.
  # The database can be indexed using: diamond makedb --in nr.gz --db diamond_nr_db --threads 24
  # This can take several hours, and will result in a file that is ~150GB in size.
  db: "/pbi/dept/appslab/datasets/dp_databases/diamond_nr_db.dmnd"
  
  # The block_size sets how many billions of letters are loaded in from the database at once.
  # Larger numbers are better, but the memory required is roughly 6x the block size.
  # If you keep the value below of 12, this will require 96GB of memory to run.
  block_size: "12"
  
  # Number of threads to use for diamond
  threads: 24
  
  # The method for limiting the number of hits reported. This should be either the -k option 
  # (max-target-seqs) or --top option. Either feature is used with the frameshift alignment mode. 
  # Using this feature along with -k 25, a hit will only be deleted if at least 
  # 50% of its query range is spanned by at least 25 higher or equal scoring hits. Using 
  # this feature along with --top 10, a hit will only be deleted if its score is more than 
  # 10% lower than that of a higher scoring hit over at least 50% of its query range.
  # I recommend -k 5 to limit hits for relatively simple metagenomics 
  # samples, and --top 5 for complex samples. Also keep in mind that more hits = larger output 
  # file size.
  hit_limit: "--top 5"
  
sam2rma:
  # The full path to the sam2rma tool.
  # This tool is distributed as part of the MEGAN download, it is a binary.
  # This can be from MEGAN community edition or ultimate edition. 
  path: "/home/dportik/programs/megan/tools/sam2rma"
  # below is example for megan-ue
  #path: "/home/dportik/programs/megan-ue/tools/sam2rma"
  
  # The full path to the MEGAN database file, which can be downloaded from:
  # https://software-ab.informatik.uni-tuebingen.de/download/megan6/welcome.html
  # please note that the name of this file will change depending on the version, 
  # and that this must be the the version for the NCBI-nr accessions.
  # Also note that there is a file for MEGAN community edition and ultimate edition,
  # with the ultimate edition containing mappings for KEGG. 
  db: "/home/dportik/programs/megan/db/megan-map-Feb2022.db"
  # below is example for megan-ue
  #db: "/home/dportik/programs/megan-ue/db/megan-map-Feb2022-ue.db"
  
  # Number of threads to use for sam2rma, 24 is generally sufficient
  threads: 24
  
  # Affects which type of RMA file to produce. When comparing taxa/functional counts, it
  # is best to use the number or reads (readCount) or the total aligned bases (alignedBases).
  # If you plan to use the RMA summary pipeline afterwards, make sure to use readCount.  
  readassignmentmode: "readCount"
  # possible values = readCount, readLength, alignedBases, readMagnitude
  
  # Minimum support as percent of assigned reads. Default in MEGAN is 0.05, but with HiFi
  # the optimized value is 0.01. This provides a balanced trade-off between precision and recall
  # (based on mock community datasets), with near perfect detection of species down to 
  # ~0.04% abundance. To avoid any filtering based on this threshold, use a value of 0 
  # instead. This will report ALL assigned reads, which will include potentially thousands 
  # of false positives at ultra-low abundances (<0.01%), similar to results from 
  # short-read methods (e.g., Kraken2, Centrifuge, etc).
  minSupportPercent: 0.01
  
rma2info:
  # The full path to the rma2info tool.
  # This tool is distributed as part of the MEGAN download, it is a binary.
  # This can be from MEGAN community edition or ultimate edition. 
  path: "/home/dportik/programs/megan/tools/rma2info"
  # below is example for megan-ue
  #path: "/home/dportik/programs/megan-ue/tools/rma2info"
    
  # Number of threads to use for rma2info. Set for memory usage of up to 5GB.
  threads: 12
  
  
# number of threads for final summary program, this may require up to 5GB memory.
summary_threads: 8